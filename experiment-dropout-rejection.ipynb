{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes:  88\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Load labels \n",
    "\n",
    "train_labels=np.load(\"train_labels.npy\")\n",
    "val_labels=np.load(\"val_labels.npy\")\n",
    "test_labels=np.load(\"test_labels.npy\")\n",
    "\n",
    "num_classes = len(np.unique(train_labels))\n",
    "print('Total classes: ',num_classes)\n",
    "\n",
    "# Encodes labels to categorical\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_num = le.transform(train_labels)\n",
    "val_labels_num = le.transform(val_labels)\n",
    "test_labels_num = le.transform(test_labels)\n",
    "\n",
    "train_labels_bin = keras.utils.to_categorical(train_labels_num, num_classes)\n",
    "val_labels_bin = keras.utils.to_categorical(val_labels_num, num_classes)\n",
    "test_labels_bin = keras.utils.to_categorical(test_labels_num, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n. layers= 3  Encoder= 3mer  Noise= 0  Padding= new\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 67, 32)            6272      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 33, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 33, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 33, 64)            6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              1025000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 88)                8888      \n",
      "=================================================================\n",
      "Total params: 1,171,172\n",
      "Trainable params: 1,171,172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 105864 samples, validate on 17324 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "105864/105864 [==============================] - 47s 446us/sample - loss: 1.0222 - acc: 0.7401 - val_loss: 1.0816 - val_acc: 0.7785\n",
      "Epoch 2/10\n",
      "105864/105864 [==============================] - 47s 446us/sample - loss: 0.2946 - acc: 0.9235 - val_loss: 0.9420 - val_acc: 0.8207\n",
      "Epoch 3/10\n",
      "105864/105864 [==============================] - 44s 420us/sample - loss: 0.2240 - acc: 0.9422 - val_loss: 0.9057 - val_acc: 0.8248\n",
      "Epoch 4/10\n",
      "105864/105864 [==============================] - 45s 422us/sample - loss: 0.1915 - acc: 0.9511 - val_loss: 0.9753 - val_acc: 0.8256\n",
      "Epoch 5/10\n",
      "105864/105864 [==============================] - 45s 426us/sample - loss: 0.1761 - acc: 0.9549 - val_loss: 0.7785 - val_acc: 0.8461\n",
      "Epoch 6/10\n",
      "105864/105864 [==============================] - 46s 432us/sample - loss: 0.1654 - acc: 0.9580 - val_loss: 0.9297 - val_acc: 0.8354\n",
      "Epoch 7/10\n",
      "105864/105864 [==============================] - 46s 438us/sample - loss: 0.1540 - acc: 0.9605 - val_loss: 0.7817 - val_acc: 0.8478\n",
      "Epoch 8/10\n",
      "105864/105864 [==============================] - 45s 427us/sample - loss: 0.1533 - acc: 0.9626 - val_loss: 0.8663 - val_acc: 0.8469\n",
      "Epoch 9/10\n",
      "105864/105864 [==============================] - 45s 428us/sample - loss: 0.1454 - acc: 0.9636 - val_loss: 0.8161 - val_acc: 0.8486\n",
      "Epoch 10/10\n",
      "105864/105864 [==============================] - 46s 436us/sample - loss: 0.1451 - acc: 0.9647 - val_loss: 0.7652 - val_acc: 0.8559\n",
      "25342/25342 [==============================] - 4s 147us/sample\n",
      " Done 25342 total records\n",
      "n. layers= 3  Encoder= 2mer  Noise= 0  Padding= new\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 100, 32)           1664      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 50, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 50, 64)            6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 25, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 25, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 12, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              1537000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 88)                8888      \n",
      "=================================================================\n",
      "Total params: 1,678,564\n",
      "Trainable params: 1,678,564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 105864 samples, validate on 17324 samples\n",
      "Epoch 1/10\n",
      "105864/105864 [==============================] - 47s 444us/sample - loss: 0.7481 - acc: 0.8163 - val_loss: 0.9794 - val_acc: 0.8121\n",
      "Epoch 2/10\n",
      "105864/105864 [==============================] - 46s 433us/sample - loss: 0.2331 - acc: 0.9407 - val_loss: 0.8338 - val_acc: 0.8313\n",
      "Epoch 3/10\n",
      "105864/105864 [==============================] - 46s 436us/sample - loss: 0.1773 - acc: 0.9550 - val_loss: 0.8032 - val_acc: 0.8527\n",
      "Epoch 4/10\n",
      "105864/105864 [==============================] - 46s 438us/sample - loss: 0.1522 - acc: 0.9613 - val_loss: 0.9280 - val_acc: 0.8374\n",
      "Epoch 5/10\n",
      "105864/105864 [==============================] - 46s 435us/sample - loss: 0.1372 - acc: 0.9652 - val_loss: 0.8510 - val_acc: 0.8494\n",
      "Epoch 6/10\n",
      "105864/105864 [==============================] - 46s 434us/sample - loss: 0.1277 - acc: 0.9673 - val_loss: 0.9839 - val_acc: 0.8502\n",
      "Epoch 7/10\n",
      "105864/105864 [==============================] - 46s 433us/sample - loss: 0.1214 - acc: 0.9700 - val_loss: 0.8589 - val_acc: 0.8573\n",
      "Epoch 8/10\n",
      "105864/105864 [==============================] - 45s 427us/sample - loss: 0.1174 - acc: 0.9709 - val_loss: 0.9411 - val_acc: 0.8574\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105864/105864 [==============================] - 45s 428us/sample - loss: 0.1142 - acc: 0.9732 - val_loss: 0.9965 - val_acc: 0.8553\n",
      "Epoch 10/10\n",
      "105864/105864 [==============================] - 46s 434us/sample - loss: 0.1148 - acc: 0.9731 - val_loss: 0.8229 - val_acc: 0.8595\n",
      "25342/25342 [==============================] - 3s 108us/sample\n",
      " Done 25342 total records\n",
      "n. layers= 3  Encoder= 1mer  Noise= 0  Padding= new\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 200, 32)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 100, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 50, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              3201000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 88)                8888      \n",
      "=================================================================\n",
      "Total params: 3,341,412\n",
      "Trainable params: 3,341,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 105864 samples, validate on 17324 samples\n",
      "Epoch 1/10\n",
      "105864/105864 [==============================] - 52s 491us/sample - loss: 0.5092 - acc: 0.8768 - val_loss: 0.9881 - val_acc: 0.8222\n",
      "Epoch 2/10\n",
      "105864/105864 [==============================] - 51s 480us/sample - loss: 0.1500 - acc: 0.9622 - val_loss: 0.9536 - val_acc: 0.8355\n",
      "Epoch 3/10\n",
      "105864/105864 [==============================] - 51s 481us/sample - loss: 0.1091 - acc: 0.9720 - val_loss: 0.9534 - val_acc: 0.8472\n",
      "Epoch 4/10\n",
      "105864/105864 [==============================] - 51s 481us/sample - loss: 0.0953 - acc: 0.9761 - val_loss: 0.9965 - val_acc: 0.8490\n",
      "Epoch 5/10\n",
      "105864/105864 [==============================] - 51s 478us/sample - loss: 0.0880 - acc: 0.9785 - val_loss: 1.0502 - val_acc: 0.8521\n",
      "Epoch 6/10\n",
      "105864/105864 [==============================] - 51s 478us/sample - loss: 0.0810 - acc: 0.9804 - val_loss: 0.9212 - val_acc: 0.8535\n",
      "Epoch 7/10\n",
      "105864/105864 [==============================] - 51s 482us/sample - loss: 0.0784 - acc: 0.9812 - val_loss: 1.1147 - val_acc: 0.8572\n",
      "Epoch 8/10\n",
      "105864/105864 [==============================] - 51s 480us/sample - loss: 0.0813 - acc: 0.9815 - val_loss: 1.0859 - val_acc: 0.8538\n",
      "Epoch 9/10\n",
      "105864/105864 [==============================] - 51s 481us/sample - loss: 0.0829 - acc: 0.9817 - val_loss: 1.2785 - val_acc: 0.8493\n",
      "Epoch 10/10\n",
      "105864/105864 [==============================] - 51s 483us/sample - loss: 0.0840 - acc: 0.9823 - val_loss: 1.1556 - val_acc: 0.8594\n",
      "25342/25342 [==============================] - 3s 110us/sample\n",
      " Done 25342 total records\n",
      "n. layers= 3  Encoder= Snake  Noise= 0  Padding= new\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 15, 15, 32)        1472      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              129000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 88)                8888      \n",
      "=================================================================\n",
      "Total params: 331,812\n",
      "Trainable params: 331,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 105864 samples, validate on 17324 samples\n",
      "Epoch 1/10\n",
      "105864/105864 [==============================] - 43s 407us/sample - loss: 1.3441 - acc: 0.6546 - val_loss: 1.5717 - val_acc: 0.6765\n",
      "Epoch 2/10\n",
      "105864/105864 [==============================] - 43s 404us/sample - loss: 0.4651 - acc: 0.8779 - val_loss: 1.3331 - val_acc: 0.7335\n",
      "Epoch 3/10\n",
      "105864/105864 [==============================] - 43s 403us/sample - loss: 0.3679 - acc: 0.9052 - val_loss: 1.1595 - val_acc: 0.7686\n",
      "Epoch 4/10\n",
      "105864/105864 [==============================] - 42s 400us/sample - loss: 0.3171 - acc: 0.9173 - val_loss: 1.1073 - val_acc: 0.7628\n",
      "Epoch 5/10\n",
      "105864/105864 [==============================] - 43s 403us/sample - loss: 0.2873 - acc: 0.9259 - val_loss: 1.0803 - val_acc: 0.7604\n",
      "Epoch 6/10\n",
      "105864/105864 [==============================] - 43s 402us/sample - loss: 0.2697 - acc: 0.9312 - val_loss: 0.9896 - val_acc: 0.7936\n",
      "Epoch 7/10\n",
      "105864/105864 [==============================] - 42s 401us/sample - loss: 0.2524 - acc: 0.9347 - val_loss: 1.0733 - val_acc: 0.7755\n",
      "Epoch 8/10\n",
      "105864/105864 [==============================] - 43s 403us/sample - loss: 0.2445 - acc: 0.9381 - val_loss: 1.0262 - val_acc: 0.7822\n",
      "Epoch 9/10\n",
      "105864/105864 [==============================] - 43s 405us/sample - loss: 0.2363 - acc: 0.9402 - val_loss: 1.0041 - val_acc: 0.7869\n",
      "Epoch 10/10\n",
      "105864/105864 [==============================] - 43s 404us/sample - loss: 0.2263 - acc: 0.9426 - val_loss: 0.9864 - val_acc: 0.7931\n",
      "25342/25342 [==============================] - 2s 96us/sample\n",
      " Done 25342 total records\n",
      "n. layers= 3  Encoder= Morton  Noise= 0  Padding= new\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 16, 16, 32)        1472      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              513000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 88)                8888      \n",
      "=================================================================\n",
      "Total params: 715,812\n",
      "Trainable params: 715,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 105864 samples, validate on 17324 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "105864/105864 [==============================] - 43s 411us/sample - loss: 1.2103 - acc: 0.6937 - val_loss: 1.4041 - val_acc: 0.7019\n",
      "Epoch 2/10\n",
      "105864/105864 [==============================] - 43s 410us/sample - loss: 0.4242 - acc: 0.8910 - val_loss: 1.3421 - val_acc: 0.7392\n",
      "Epoch 3/10\n",
      "105864/105864 [==============================] - 43s 411us/sample - loss: 0.3354 - acc: 0.9122 - val_loss: 1.3110 - val_acc: 0.7480\n",
      "Epoch 4/10\n",
      "105864/105864 [==============================] - 43s 410us/sample - loss: 0.2941 - acc: 0.9233 - val_loss: 1.2417 - val_acc: 0.7486\n",
      "Epoch 5/10\n",
      "105864/105864 [==============================] - 44s 411us/sample - loss: 0.2741 - acc: 0.9296 - val_loss: 1.0894 - val_acc: 0.7782\n",
      "Epoch 6/10\n",
      "105864/105864 [==============================] - 43s 409us/sample - loss: 0.2551 - acc: 0.9347 - val_loss: 1.1338 - val_acc: 0.7775\n",
      "Epoch 7/10\n",
      "105864/105864 [==============================] - 43s 409us/sample - loss: 0.2432 - acc: 0.9381 - val_loss: 1.1026 - val_acc: 0.7735\n",
      "Epoch 8/10\n",
      "105864/105864 [==============================] - 43s 406us/sample - loss: 0.2377 - acc: 0.9398 - val_loss: 1.1459 - val_acc: 0.7580\n",
      "Epoch 9/10\n",
      "105864/105864 [==============================] - 43s 407us/sample - loss: 0.2253 - acc: 0.9435 - val_loss: 1.1543 - val_acc: 0.7636\n",
      "Epoch 10/10\n",
      "105864/105864 [==============================] - 44s 411us/sample - loss: 0.2213 - acc: 0.9452 - val_loss: 1.1647 - val_acc: 0.7798\n",
      "25342/25342 [==============================] - 2s 93us/sample\n",
      " Done 25342 total records\n",
      "n. layers= 3  Encoder= Hilbert  Noise= 0  Padding= new\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 16, 16, 32)        1472      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              513000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 88)                8888      \n",
      "=================================================================\n",
      "Total params: 715,812\n",
      "Trainable params: 715,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 105864 samples, validate on 17324 samples\n",
      "Epoch 1/10\n",
      "105864/105864 [==============================] - 43s 404us/sample - loss: 1.1051 - acc: 0.7209 - val_loss: 1.3361 - val_acc: 0.7262\n",
      "Epoch 2/10\n",
      "105864/105864 [==============================] - 42s 400us/sample - loss: 0.3716 - acc: 0.9028 - val_loss: 1.2221 - val_acc: 0.7479\n",
      "Epoch 3/10\n",
      "105864/105864 [==============================] - 42s 400us/sample - loss: 0.2950 - acc: 0.9237 - val_loss: 1.3646 - val_acc: 0.7573\n",
      "Epoch 4/10\n",
      "105864/105864 [==============================] - 42s 399us/sample - loss: 0.2604 - acc: 0.9327 - val_loss: 1.1489 - val_acc: 0.7727\n",
      "Epoch 5/10\n",
      "105864/105864 [==============================] - 42s 401us/sample - loss: 0.2425 - acc: 0.9378 - val_loss: 1.2271 - val_acc: 0.7611\n",
      "Epoch 6/10\n",
      "105864/105864 [==============================] - 42s 400us/sample - loss: 0.2306 - acc: 0.9416 - val_loss: 1.1290 - val_acc: 0.7779\n",
      "Epoch 7/10\n",
      "105864/105864 [==============================] - 42s 400us/sample - loss: 0.2162 - acc: 0.9457 - val_loss: 1.1248 - val_acc: 0.7865\n",
      "Epoch 8/10\n",
      "105864/105864 [==============================] - 42s 401us/sample - loss: 0.2161 - acc: 0.9458 - val_loss: 1.2072 - val_acc: 0.7724\n",
      "Epoch 9/10\n",
      "105864/105864 [==============================] - 42s 401us/sample - loss: 0.2075 - acc: 0.9487 - val_loss: 1.1735 - val_acc: 0.7851\n",
      "Epoch 10/10\n",
      "105864/105864 [==============================] - 42s 398us/sample - loss: 0.2043 - acc: 0.9498 - val_loss: 1.1851 - val_acc: 0.7824\n",
      "25342/25342 [==============================] - 2s 88us/sample\n",
      " Done 25342 total records\n"
     ]
    }
   ],
   "source": [
    "# Train a model on a training set without random class\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from utils.ExpConfiguration import *\n",
    "from utils.modelUtils import *\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import f1_score\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "\n",
    "padd = 'new' # CHANGE HERE to select other padding schemas (new, constant, random)\n",
    "\n",
    "testfile = 'test_rndseq_t1.fasta'\n",
    "test_labels_rnd = get_labels(testfile)\n",
    "seqTestRnd = get_seqs_with_bnoise(testfile,nperc=0)\n",
    "\n",
    "\n",
    "y_true = np.argmax(test_labels_bin, axis=1)\n",
    "y_true = le.inverse_transform(y_true)\n",
    "labels,lcounts = np.unique(y_true,return_counts=True)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "nl = 3\n",
    "bn = 0\n",
    "\n",
    "mc = 50 # number of runs\n",
    "\n",
    "outdata = {}\n",
    "\n",
    "for en in seqEncoders:\n",
    "    print('n. layers=',nl,' Encoder=',en['filename'],' Noise=',str(bn), ' Padding=',padd)\n",
    "    train_seq=np.load('train_' + en['filename'] + '_' + padd + '_' + str(bn) + '_seq.npy')\n",
    "    val_seq=np.load('val_' + en['filename'] + '_' + padd + '_' + str(bn) + '_seq.npy')\n",
    "    test_seq=np.load('test_' + en['filename'] + '_' + padd + '_' + str(bn) + '_seq.npy')\n",
    "\n",
    "    train_seq = keras.utils.to_categorical(train_seq)\n",
    "    val_seq = keras.utils.to_categorical(val_seq)\n",
    "    test_seq = keras.utils.to_categorical(test_seq)\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    if (en['filename'] in ['1mer','2mer','3mer']):\n",
    "        m=buildCNNModel(inshape=train_seq.shape[1:],num_classes=num_classes,nlayers=nl,cnndim=1)\n",
    "    else:\n",
    "        m=buildCNNModel(inshape=train_seq.shape[1:],num_classes=num_classes,nlayers=nl,cnndim=2)\n",
    "\n",
    "    print(m.summary())\n",
    "\n",
    "    m.compile(optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    m.fit(train_seq, train_labels_bin,verbose=1,\n",
    "                  batch_size=batch_size,shuffle=True,\n",
    "                  epochs=epochs,#validation_split=0.33,\n",
    "                  validation_data=(val_seq, val_labels_bin))\n",
    "    \n",
    "    pred = m.predict(test_seq, verbose=1)\n",
    "    predicted = np.argmax(pred, axis=1)\n",
    "    y_pred = le.inverse_transform(predicted)\n",
    "\n",
    "\n",
    "    model_mc = K.function([m.input, K.learning_phase()], [m.output])\n",
    "    \n",
    "    # Generate random samples\n",
    "\n",
    "    test_seq_rnd = encode_seqs(seqTestRnd,enc=en['enc'],encparam=en['param'+str(bn)],padding=padd)\n",
    "    test_seq_rnd = keras.utils.to_categorical(test_seq_rnd)\n",
    "\n",
    "    avrp_rnd = np.zeros((len(test_seq_rnd),num_classes))\n",
    "    avrp_nornd = np.zeros((len(test_seq),num_classes))\n",
    "\n",
    "    fp_rnd = np.zeros((len(test_seq_rnd),num_classes))\n",
    "    fp_nornd = np.zeros((len(test_seq),num_classes))\n",
    "\n",
    "    avrhp_rnd = np.zeros((len(test_seq_rnd)))\n",
    "    avrhp_nornd = np.zeros((len(test_seq)))\n",
    "\n",
    "    p_rnd = np.zeros((mc,len(test_seq_rnd),num_classes))\n",
    "    p_nornd = np.zeros((mc,len(test_seq),num_classes))\n",
    "\n",
    "    for i in range(mc):\n",
    "        preds_nornd=model_mc([test_seq,1])\n",
    "        p_nornd[i,:,:] = preds_nornd[0]\n",
    "        avrp_nornd = avrp_nornd + preds_nornd[0]\n",
    "        avrhp_nornd = avrhp_nornd + np.sum(-preds_nornd[0]*np.log2(preds_nornd[0]+1e-10),1)\n",
    "        midx = np.argmax(preds_nornd[0],1)\n",
    "        for j in range(len(test_seq)):\n",
    "            fp_nornd[j,midx[j]] = fp_nornd[j,midx[j]] + 1\n",
    "\n",
    "        preds_rnd=model_mc([test_seq_rnd,1])\n",
    "        p_rnd[i,:,:] = preds_rnd[0]\n",
    "        avrp_rnd = avrp_rnd + preds_rnd[0]\n",
    "        avrhp_rnd = avrhp_rnd + np.sum(-preds_rnd[0]*np.log2(preds_rnd[0]+1e-10),1)\n",
    "        midx = np.argmax(preds_rnd[0],1)\n",
    "        for j in range(len(test_seq_rnd)):\n",
    "            fp_rnd[j,midx[j]] = fp_rnd[j,midx[j]] + 1\n",
    "\n",
    "\n",
    "    avrp_rnd = avrp_rnd/mc\n",
    "    avrp_nornd = avrp_nornd/mc\n",
    "    fp_rnd = fp_rnd/mc\n",
    "    fp_nornd = fp_nornd/mc\n",
    "    avrhp_rnd = avrhp_rnd/mc\n",
    "    avrhp_nornd = avrhp_nornd/mc\n",
    "\n",
    "        # compute indicators entropy (hp) variance (var) max prob (maxp) and f max\n",
    "\n",
    "    hp_nornd = np.sum(-avrp_nornd*np.log2(avrp_nornd+1e-10),1)\n",
    "    hp_rnd = np.sum(-avrp_rnd*np.log2(avrp_rnd+1e-10),1)\n",
    "\n",
    "    var_rnd = np.var(p_rnd,0)\n",
    "    var_nornd = np.var(p_nornd,0)\n",
    "\n",
    "    orderp_rnd = np.argsort(-avrp_rnd,1)\n",
    "    orderp_nornd = np.argsort(-avrp_nornd,1)\n",
    "\n",
    "    maxp_nornd = np.max(avrp_nornd,1)\n",
    "    maxp_rnd = np.max(avrp_rnd,1)\n",
    "    maxfp_nornd = np.max(fp_nornd,1)\n",
    "    maxfp_rnd = np.max(fp_rnd,1)\n",
    "    \n",
    "    indicators={}\n",
    "    indicators.update({'hp_rnd' : hp_rnd})\n",
    "    indicators.update({'hp_nornd' : hp_nornd})\n",
    "    indicators.update({'avrhp_rnd' : avrhp_rnd})\n",
    "    indicators.update({'avrhp_nornd' : avrhp_nornd})\n",
    "    indicators.update({'orderp_rnd' : orderp_rnd})\n",
    "    indicators.update({'orderp_nornd' : orderp_nornd})\n",
    "    indicators.update({'maxp_rnd' : maxp_rnd})\n",
    "    indicators.update({'maxp_nornd' : maxp_nornd})\n",
    "    indicators.update({'maxfp_rnd' : maxfp_rnd})\n",
    "    indicators.update({'maxfp_nornd' : maxfp_nornd})\n",
    "    indicators.update({'avrp_rnd' : avrp_rnd})\n",
    "    indicators.update({'avrp_nornd' : avrp_nornd})\n",
    "    indicators.update({'var_rnd' : var_rnd})\n",
    "    indicators.update({'var_nornd' : var_nornd})\n",
    "\n",
    "    indicators.update({'y_pred' : y_pred})\n",
    "\n",
    "\n",
    "    outdata.update({en['filename'] : indicators})\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save results on file\n",
    "f = open('results/RejectionExperiments_' + padd + '.pckl', 'wb')\n",
    "pickle.dump(outdata, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
