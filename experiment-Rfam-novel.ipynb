{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Experiments on _Rfam novel_ datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sklearn\n",
    "import tensorflow\n",
    "import matplotlib\n",
    "import pandas\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(sklearn.__version__)\n",
    "print(numpy.__version__)\n",
    "print(matplotlib.__version__)\n",
    "print(pandas.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Load labels \n",
    "\n",
    "train_labels=np.load(\"train_labels.npy\")\n",
    "val_labels=np.load(\"val_labels.npy\")\n",
    "test_labels=np.load(\"test_labels.npy\")\n",
    "\n",
    "num_classes = len(np.unique(train_labels))\n",
    "print('Total classes: ',num_classes)\n",
    "\n",
    "# Encodes labels to categorical\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_num = le.transform(train_labels)\n",
    "val_labels_num = le.transform(val_labels)\n",
    "test_labels_num = le.transform(test_labels)\n",
    "\n",
    "train_labels_bin = keras.utils.to_categorical(train_labels_num, num_classes)\n",
    "val_labels_bin = keras.utils.to_categorical(val_labels_num, num_classes)\n",
    "test_labels_bin = keras.utils.to_categorical(test_labels_num, num_classes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ExpConfiguration import *\n",
    "from utils.modelUtils import *\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import f1_score\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "\n",
    "padd = 'random' # CHANGE HERE to select other padding schemas (new, constant, random)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# where results are stored\n",
    "v_acc = {}\n",
    "\n",
    "for nl in nlayers:\n",
    "    venc = {}\n",
    "    for en in seqEncoders:\n",
    "        vbnoise = {}\n",
    "        for bn in bnoise:\n",
    "            print('n. layers=',nl,' Encoder=',en['filename'],' Noise=',str(bn), ' Padding=',padd)\n",
    "            train_seq=np.load('train_' + en['filename'] + '_' + padd + '_' + str(bn) + '_seq.npy')\n",
    "            val_seq=np.load('val_' + en['filename'] + '_' + padd + '_' + str(bn) + '_seq.npy')\n",
    "            test_seq=np.load('test_' + en['filename'] + '_' + padd + '_' + str(bn) + '_seq.npy')\n",
    "\n",
    "            if (nl>0):\n",
    "                train_seq = keras.utils.to_categorical(train_seq)\n",
    "                val_seq = keras.utils.to_categorical(val_seq)\n",
    "                test_seq = keras.utils.to_categorical(test_seq)\n",
    "            else:\n",
    "                train_seq = train_seq.reshape((-1,np.prod(train_seq.shape[1:])))\n",
    "                val_seq = val_seq.reshape((-1,np.prod(val_seq.shape[1:])))\n",
    "                test_seq = test_seq.reshape((-1,np.prod(test_seq.shape[1:])))\n",
    "                nmax = np.max(train_seq)\n",
    "                train_seq = train_seq/nmax\n",
    "                val_seq = val_seq/nmax\n",
    "                test_seq = test_seq/nmax\n",
    "\n",
    "            tf.keras.backend.clear_session()\n",
    "            print(train_seq.shape)\n",
    "            print(val_seq.shape)\n",
    "            print(test_seq.shape)\n",
    "            if (en['filename'] in ['1mer','2mer','3mer']):\n",
    "                m=buildCNNModel(inshape=train_seq.shape[1:],num_classes=num_classes,nlayers=nl,cnndim=1)\n",
    "            else:\n",
    "                m=buildCNNModel(inshape=train_seq.shape[1:],num_classes=num_classes,nlayers=nl,cnndim=2)\n",
    "            print(m.summary())\n",
    "            m.compile(optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "            m.fit(train_seq, train_labels_bin,verbose=1,\n",
    "                  batch_size=batch_size,shuffle=True,\n",
    "                  epochs=epochs,#validation_split=0.33,\n",
    "                  validation_data=(val_seq, val_labels_bin))\n",
    "\n",
    "            pred = m.predict(test_seq, verbose=1)\n",
    "            predicted = np.argmax(pred, axis=1)\n",
    "            \n",
    "            vbnoise.update({str(bn) : predicted})\n",
    "        venc.update({en['filename'] : vbnoise})\n",
    "    v_acc.update({str(nl) : venc})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save results on file\n",
    "f = open('results/RfamNovel_' + padd + '.pckl', 'wb')\n",
    "pickle.dump(v_acc, f)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
