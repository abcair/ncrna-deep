{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Experiments on _Rfam novel_ datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "0.21.3\n",
      "1.18.5\n",
      "3.1.1\n",
      "0.24.2\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import sklearn\n",
    "import tensorflow\n",
    "import matplotlib\n",
    "import pandas\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(sklearn.__version__)\n",
    "print(numpy.__version__)\n",
    "print(matplotlib.__version__)\n",
    "print(pandas.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes:  88\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Load labels \n",
    "\n",
    "train_labels=np.load(\"train_labels.npy\")\n",
    "val_labels=np.load(\"val_labels.npy\")\n",
    "test_labels=np.load(\"test_labels.npy\")\n",
    "\n",
    "num_classes = len(np.unique(train_labels))\n",
    "print('Total classes: ',num_classes)\n",
    "\n",
    "# Encodes labels to categorical\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_num = le.transform(train_labels)\n",
    "val_labels_num = le.transform(val_labels)\n",
    "test_labels_num = le.transform(test_labels)\n",
    "\n",
    "train_labels_bin = keras.utils.to_categorical(train_labels_num, num_classes)\n",
    "val_labels_bin = keras.utils.to_categorical(val_labels_num, num_classes)\n",
    "test_labels_bin = keras.utils.to_categorical(test_labels_num, num_classes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n. layers= 0  Encoder= 3mer  Noise= 0  Padding= new\n",
      "(105864, 67)\n",
      "(17324, 67)\n",
      "(25342, 67)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 500)               34000     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              501000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 88)                8888      \n",
      "=================================================================\n",
      "Total params: 643,988\n",
      "Trainable params: 643,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 105864 samples, validate on 17324 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "105864/105864 [==============================] - 32s 303us/sample - loss: 1.4661 - acc: 0.6408 - val_loss: 3.1656 - val_acc: 0.3419\n",
      "Epoch 2/20\n",
      "105864/105864 [==============================] - 30s 283us/sample - loss: 0.9264 - acc: 0.7650 - val_loss: 3.2011 - val_acc: 0.3837\n",
      "Epoch 3/20\n",
      "105864/105864 [==============================] - 30s 283us/sample - loss: 0.7628 - acc: 0.8047 - val_loss: 3.0036 - val_acc: 0.4361\n",
      "Epoch 4/20\n",
      "105864/105864 [==============================] - 30s 283us/sample - loss: 0.6712 - acc: 0.8274 - val_loss: 3.1185 - val_acc: 0.3998\n",
      "Epoch 5/20\n",
      "105864/105864 [==============================] - 30s 280us/sample - loss: 0.6067 - acc: 0.8435 - val_loss: 2.9718 - val_acc: 0.4360\n",
      "Epoch 6/20\n",
      " 82144/105864 [======================>.......] - ETA: 6s - loss: 0.5618 - acc: 0.8537"
     ]
    }
   ],
   "source": [
    "from utils.ExpConfiguration import *\n",
    "from utils.modelUtils import *\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import f1_score\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "\n",
    "padd = 'new' # CHANGE HERE to select other padding schemas (new, constant, random)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "# where results are stored\n",
    "v_acc = {}\n",
    "\n",
    "for nl in nlayers:\n",
    "    venc = {}\n",
    "    for en in seqEncoders:\n",
    "        vbnoise = {}\n",
    "        for bn in bnoise:\n",
    "            print('n. layers=',nl,' Encoder=',en['filename'],' Noise=',str(bn), ' Padding=',padd)\n",
    "            train_seq=np.load('train_' + en['filename'] + '_' + padd + '_' + str(bn) + '_seq.npy')\n",
    "            val_seq=np.load('val_' + en['filename'] + '_' + padd + '_' + str(bn) + '_seq.npy')\n",
    "            test_seq=np.load('test_' + en['filename'] + '_' + padd + '_' + str(bn) + '_seq.npy')\n",
    "\n",
    "            if (nl>0):\n",
    "                train_seq = keras.utils.to_categorical(train_seq)\n",
    "                val_seq = keras.utils.to_categorical(val_seq)\n",
    "                test_seq = keras.utils.to_categorical(test_seq)\n",
    "            else:\n",
    "                train_seq = train_seq.reshape((-1,np.prod(train_seq.shape[1:])))\n",
    "                val_seq = val_seq.reshape((-1,np.prod(val_seq.shape[1:])))\n",
    "                test_seq = test_seq.reshape((-1,np.prod(test_seq.shape[1:])))\n",
    "                nmax = np.max(train_seq)\n",
    "                train_seq = train_seq/nmax\n",
    "                val_seq = val_seq/nmax\n",
    "                test_seq = test_seq/nmax\n",
    "\n",
    "            tf.keras.backend.clear_session()\n",
    "            print(train_seq.shape)\n",
    "            print(val_seq.shape)\n",
    "            print(test_seq.shape)\n",
    "            if (en['filename'] in ['1mer','2mer','3mer']):\n",
    "                m=buildCNNModel(inshape=train_seq.shape[1:],num_classes=num_classes,nlayers=nl,cnndim=1)\n",
    "            else:\n",
    "                m=buildCNNModel(inshape=train_seq.shape[1:],num_classes=num_classes,nlayers=nl,cnndim=2)\n",
    "            print(m.summary())\n",
    "            m.compile(optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "            m.fit(train_seq, train_labels_bin,verbose=1,\n",
    "                  batch_size=batch_size,shuffle=True,\n",
    "                  epochs=epochs,#validation_split=0.33,\n",
    "                  validation_data=(val_seq, val_labels_bin))\n",
    "\n",
    "            pred = m.predict(test_seq, verbose=1)\n",
    "            predicted = np.argmax(pred, axis=1)\n",
    "            \n",
    "            vbnoise.update({str(bn) : predicted})\n",
    "        venc.update({en['filename'] : vbnoise})\n",
    "    v_acc.update({str(nl) : venc})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save results on file\n",
    "f = open('results/RfamNovel_' + padd + '.pckl', 'wb')\n",
    "pickle.dump(v_acc, f)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
