{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on _RNAGCN/nRC_ datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Load labels and encodes as categories\n",
    "\n",
    "train_labels=np.load(\"dataset_nRC_train_labels.npy\")\n",
    "test_labels=np.load(\"dataset_nRC_test_labels.npy\")\n",
    "\n",
    "num_classes = len(np.unique(train_labels))\n",
    "print('Total classes: ',num_classes)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_num = le.transform(train_labels)\n",
    "test_labels_num = le.transform(test_labels)\n",
    "\n",
    "train_labels_bin = keras.utils.to_categorical(train_labels_num, num_classes)\n",
    "test_labels_bin = keras.utils.to_categorical(test_labels_num, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExpConfiguration import *\n",
    "from modelUtils import *\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import f1_score\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "p ='new' # CHANGE HERE to select other padding schemas (new, constant, random)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# where results are stored\n",
    "v_acc = {}\n",
    "\n",
    "nl=3 # number of CNN layers\n",
    "\n",
    "venc = {}\n",
    "for en in seqEncoders:\n",
    "    print(en['filename'])\n",
    "    train_seq=np.load('dataset_nRC_train_' + en['filename'] + '_'+p+'_seq.npy')\n",
    "    test_seq=np.load('dataset_nRC_test_' + en['filename'] + '_'+p+'_seq.npy')\n",
    "\n",
    "    train_seq = keras.utils.to_categorical(train_seq)\n",
    "    test_seq = keras.utils.to_categorical(test_seq)\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    print(train_seq.shape)\n",
    "    print(test_seq.shape)\n",
    "    if (en['filename'] in ['1mer','2mer','3mer']):\n",
    "        m=buildCNNModel2(inshape=train_seq.shape[1:],num_classes=num_classes,nlayers=nl,cnndim=1)\n",
    "    else:\n",
    "        m=buildCNNModel2(inshape=train_seq.shape[1:],num_classes=num_classes,nlayers=nl,cnndim=2)\n",
    "    m.compile(optimizer=keras.optimizers.Adam(lr=.0005),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    m.summary()\n",
    "    m.fit(train_seq, train_labels_bin,verbose=1,\n",
    "                  batch_size=batch_size,shuffle=True,\n",
    "                  epochs=epochs,validation_split=0.1)\n",
    "\n",
    "            \n",
    "    pred = m.predict(test_seq, verbose=1)\n",
    "    predicted = np.argmax(pred, axis=1)\n",
    "    venc.update({en['filename'] : {'0' : predicted}})\n",
    "v_acc.update({str(nl) : venc})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save results on file\n",
    "f = open('results/store_acc_datasetnRC_' + padd + '.pckl', 'wb')\n",
    "pickle.dump(v_acc, f)\n",
    "f.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
