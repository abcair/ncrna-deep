{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of tables and figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "v_acc_d = {}\n",
    "\n",
    "f = open('results/RfamNovel_constant.pckl', 'rb')\n",
    "v_acc_d.update({'Constant' : pickle.load(f)})\n",
    "f.close()\n",
    "\n",
    "f = open('results/RfamNovel_random.pckl', 'rb')\n",
    "v_acc_d.update({'Random' : pickle.load(f)})\n",
    "f.close()\n",
    "\n",
    "f = open('results/RfamNovel_new.pckl', 'rb')\n",
    "v_acc_d.update({'New' : pickle.load(f)})\n",
    "f.close()\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "train_labels=np.load(\"train_labels.npy\")\n",
    "val_labels=np.load(\"val_labels.npy\")\n",
    "test_labels=np.load(\"test_labels.npy\")\n",
    "\n",
    "num_classes = len(np.unique(train_labels))\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_num = le.transform(train_labels)\n",
    "val_labels_num = le.transform(val_labels)\n",
    "test_labels_num = le.transform(test_labels)\n",
    "\n",
    "train_labels_bin = keras.utils.to_categorical(train_labels_num, num_classes)\n",
    "val_labels_bin = keras.utils.to_categorical(val_labels_num, num_classes)\n",
    "test_labels_bin = keras.utils.to_categorical(test_labels_num, num_classes)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots the accuracy/MCC vs boundary noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots accuracy or MCC VS bnoise\n",
    "from sklearn.metrics import *\n",
    "from ExpConfiguration import *\n",
    "from math import sqrt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "y_true = np.argmax(test_labels_bin, axis=1)\n",
    "\n",
    "# CHANGE HERE plot parameters\n",
    "nl=3  # cnn layer to plot\n",
    "#padd = 'Constant'\n",
    "#padd = 'Random'\n",
    "padd = 'New' \n",
    "#pmetric = 'MCC'\n",
    "#pmetricf = matthews_corrcoef\n",
    "pmetric = 'ACC'\n",
    "pmetricf = accuracy_score\n",
    "#pmetric = 'F1'\n",
    "#def f11_score(x,y): \n",
    "#    return f1_score(x,y,average='macro')\n",
    "\n",
    "#pmetricf = f11_score\n",
    "#pmetric = 'KAPPA'\n",
    "#pmetricf = cohen_kappa_score\n",
    "\n",
    "v_acc = v_acc_d[padd]\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('Boundary noise')\n",
    "plt.ylabel(pmetric)\n",
    "#plt.title('CNN n. layers = '+str(nl))\n",
    "plt.ylim(0.5, 1) \n",
    "for en in seqEncoders:\n",
    "    mtr=[]\n",
    "    mtrErr=[]\n",
    "    for bn in bnoise:\n",
    "        y_pred = v_acc[str(nl)][en['filename']][str(bn)]\n",
    "        #print('%.3f' % interval)\n",
    "        mtr.append(pmetricf(y_true,y_pred))\n",
    "        #mtrErr.append(1.96 * sqrt( (pmetricf(y_true,y_pred) * (1 - pmetricf(y_true,y_pred))) / len(y_pred)))\n",
    "        #print(en['filename'],bn,matthews_corrcoef(y_true,y_pred),accuracy_score(y_true,y_pred))\n",
    "            \n",
    "    ax.plot(bnoise, mtr, label=en['filename'],marker='o',markersize=3)\n",
    "    #ax.errorbar(bnoise, mtr, yerr=mtrErr)\n",
    "\n",
    "# add Eden results\n",
    "mtr=[]\n",
    "for bn in bnoise:\n",
    "    y_pred = np.loadtxt('eden/test_pred_eden_'+str(bn)+'.txt',dtype='str')\n",
    "    y_true = np.loadtxt('eden/test_labels_eden_'+str(bn)+'.txt',dtype='str')\n",
    "    mtr.append(pmetricf(y_true,y_pred))\n",
    "    #mtr.append(accuracy_score(y_true,y_pred))\n",
    "    #print('EdeN',bn,matthews_corrcoef(y_true,y_pred),accuracy_score(y_true,y_pred))\n",
    "\n",
    "ax.plot(bnoise, mtr, label='EdeN',marker='o',markersize=3)\n",
    "# add nRC results\n",
    "mtr=[]\n",
    "for bn in bnoise:\n",
    "    y_pred = np.loadtxt('nrc/test_pred_nrc_'+str(bn)+'.txt',dtype='str')\n",
    "    y_true = np.loadtxt('nrc/test_labels_nrc_'+str(bn)+'.txt',dtype='str')\n",
    "    mtr.append(pmetricf(y_true,y_pred))\n",
    "    #print('nRC',bn,matthews_corrcoef(y_true,y_pred),accuracy_score(y_true,y_pred))\n",
    "\n",
    "\n",
    "ax.plot(bnoise, mtr, label='nRC',marker='o',markersize=3)\n",
    "ax.legend()\n",
    "ax.grid(linestyle='--')\n",
    "plt.grid(True)\n",
    "plt.savefig('figs/plot_bnoise-m'+pmetric+'_nl'+str(nl)+'_p'+padd+'.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots accuracy with different padding schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from ExpConfiguration import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# CHANGE HERE plot parameters\n",
    "nl=3  # cnn layer to plot\n",
    "bn = 0 # boundary noise\n",
    "#pmetric = 'MCC'\n",
    "#pmetricf = matthews_corrcoef\n",
    "pmetric = 'ACC'\n",
    "pmetricf = accuracy_score\n",
    "\n",
    "\n",
    "y_true = np.argmax(test_labels_bin, axis=1)\n",
    "index = ['New', 'Constant', 'Random']\n",
    "cols = {}\n",
    "colsErr = {}\n",
    "for en in seqEncoders:\n",
    "    y_pred = v_acc_d['New'][str(nl)][en['filename']][str(bn)]\n",
    "    pnew = pmetricf(y_true,y_pred)\n",
    "    pnewInt = 1.96 * sqrt( (pnew * (1 - pnew)) / len(y_pred))\n",
    "\n",
    "    y_pred = v_acc_d['Constant'][str(nl)][en['filename']][str(bn)]\n",
    "    pcns = pmetricf(y_true,y_pred)\n",
    "    pcnsInt = 1.96 * sqrt( (pcns * (1 - pcns)) / len(y_pred))\n",
    "\n",
    "    y_pred = v_acc_d['Random'][str(nl)][en['filename']][str(bn)]\n",
    "    prnd = pmetricf(y_true,y_pred)\n",
    "    prndInt = 1.96 * sqrt( (prnd * (1 - prnd)) / len(y_pred))\n",
    "\n",
    "    errors = [pnewInt,pcnsInt,prndInt]\n",
    "    performance = [pnew,pcns,prnd]\n",
    "    cols.update({en['filename'] : performance})\n",
    "    colsErr.update({en['filename'] : errors})\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(cols, index=index)\n",
    "dfErr = pd.DataFrame(colsErr, index=index)\n",
    "ax = df.plot.bar(rot=0,ylim=(0.5,1),yerr=dfErr)\n",
    "ax.grid(linestyle='--')\n",
    "plt.grid(True)\n",
    "ax.legend(loc='lower left')\n",
    "#plt.title('Input padding symbol')\n",
    "plt.ylabel('ACC')\n",
    "plt.savefig('figs/plot-padding.pdf')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots accuracy/MCC with different CNN n. of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from ExpConfiguration import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# CHANGE HERE plot parameters\n",
    "bn = 0 # boundary noise\n",
    "padd = 'New'  # padding to plot\n",
    "#pmetric = 'MCC'\n",
    "#pmetricf = matthews_corrcoef\n",
    "pmetric = 'ACC'\n",
    "pmetricf = accuracy_score\n",
    "\n",
    "\n",
    "y_true = np.argmax(test_labels_bin, axis=1)\n",
    "index = ['0', '1', '2','3']\n",
    "cols = {}\n",
    "for en in seqEncoders:\n",
    "    y_pred = v_acc[str(0)][en['filename']][str(bn)]\n",
    "    p0 = pmetricf(y_true,y_pred)\n",
    "    p0E = 1.96 * sqrt( (p0 * (1 - p0)) / len(y_pred))\n",
    "    y_pred = v_acc[str(1)][en['filename']][str(bn)]\n",
    "    p1 = pmetricf(y_true,y_pred)\n",
    "    p1E = 1.96 * sqrt( (p1 * (1 - p1)) / len(y_pred))\n",
    "\n",
    "    y_pred = v_acc[str(2)][en['filename']][str(bn)]\n",
    "    p2 = pmetricf(y_true,y_pred)\n",
    "    p2E = 1.96 * sqrt( (p2 * (1 - p2)) / len(y_pred))\n",
    "\n",
    "    y_pred = v_acc[str(3)][en['filename']][str(bn)]\n",
    "    p3 = pmetricf(y_true,y_pred)\n",
    "    p3E = 1.96 * sqrt( (p3 * (1 - p3)) / len(y_pred))\n",
    "\n",
    "    \n",
    "    performance = [p0,p1,p2,p3]\n",
    "    errors = [p0E,p1E,p2E,p3E]\n",
    "    cols.update({en['filename'] : performance})\n",
    "    colsErr.update({en['filename'] : errors})\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(cols, index=index)\n",
    "dfErr = pd.DataFrame(colsErr, index=index)\n",
    "ax = df.plot.bar(rot=0,ylim=(0.5,1),yerr=dfErr)\n",
    "ax.grid(linestyle='--')\n",
    "plt.grid(True)\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "#plt.title('CNN number of layers')\n",
    "plt.ylabel('ACC')\n",
    "plt.xlabel('CNN n. of layers')\n",
    "plt.savefig('figs/plot-cnnlayers.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generates tables with precisions, recalls, and F1-measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3mer</th>\n",
       "      <th>2mer</th>\n",
       "      <th>1mer</th>\n",
       "      <th>Snake</th>\n",
       "      <th>Morton</th>\n",
       "      <th>Hilbert</th>\n",
       "      <th>EdeN</th>\n",
       "      <th>nRC</th>\n",
       "      <th>Class size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF00001</th>\n",
       "      <td>0.942557</td>\n",
       "      <td>0.880391</td>\n",
       "      <td>0.941272</td>\n",
       "      <td>0.931369</td>\n",
       "      <td>0.867303</td>\n",
       "      <td>0.863788</td>\n",
       "      <td>0.912135</td>\n",
       "      <td>0.899425</td>\n",
       "      <td>3886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00005</th>\n",
       "      <td>0.941100</td>\n",
       "      <td>0.942291</td>\n",
       "      <td>0.941098</td>\n",
       "      <td>0.939531</td>\n",
       "      <td>0.931964</td>\n",
       "      <td>0.919448</td>\n",
       "      <td>0.934906</td>\n",
       "      <td>0.932784</td>\n",
       "      <td>2315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00015</th>\n",
       "      <td>0.904177</td>\n",
       "      <td>0.909502</td>\n",
       "      <td>0.918269</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.819843</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.865217</td>\n",
       "      <td>0.898488</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00016</th>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.789157</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.477157</td>\n",
       "      <td>0.410853</td>\n",
       "      <td>0.779116</td>\n",
       "      <td>0.859504</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00019</th>\n",
       "      <td>0.976242</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.977099</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.976087</td>\n",
       "      <td>0.975930</td>\n",
       "      <td>0.980603</td>\n",
       "      <td>0.979280</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00020</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.154639</td>\n",
       "      <td>0.323353</td>\n",
       "      <td>0.184971</td>\n",
       "      <td>0.131944</td>\n",
       "      <td>0.106977</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>0.880829</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00026</th>\n",
       "      <td>0.967638</td>\n",
       "      <td>0.963437</td>\n",
       "      <td>0.952737</td>\n",
       "      <td>0.970248</td>\n",
       "      <td>0.953297</td>\n",
       "      <td>0.953061</td>\n",
       "      <td>0.980849</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00029</th>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00050</th>\n",
       "      <td>0.986877</td>\n",
       "      <td>0.914148</td>\n",
       "      <td>0.993412</td>\n",
       "      <td>0.948035</td>\n",
       "      <td>0.980341</td>\n",
       "      <td>0.972621</td>\n",
       "      <td>0.967908</td>\n",
       "      <td>0.967658</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00059</th>\n",
       "      <td>0.968193</td>\n",
       "      <td>0.974704</td>\n",
       "      <td>0.967864</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.932553</td>\n",
       "      <td>0.951275</td>\n",
       "      <td>0.948782</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00066</th>\n",
       "      <td>0.883562</td>\n",
       "      <td>0.894915</td>\n",
       "      <td>0.724868</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.849498</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.932384</td>\n",
       "      <td>0.897010</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00097</th>\n",
       "      <td>0.968706</td>\n",
       "      <td>0.958571</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.961702</td>\n",
       "      <td>0.852800</td>\n",
       "      <td>0.926756</td>\n",
       "      <td>0.950345</td>\n",
       "      <td>0.958960</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00156</th>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.445498</td>\n",
       "      <td>0.251716</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00162</th>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.972763</td>\n",
       "      <td>0.927419</td>\n",
       "      <td>0.925620</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.877863</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00169</th>\n",
       "      <td>0.904110</td>\n",
       "      <td>0.943878</td>\n",
       "      <td>0.952128</td>\n",
       "      <td>0.904110</td>\n",
       "      <td>0.792913</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.927389</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00504</th>\n",
       "      <td>0.943548</td>\n",
       "      <td>0.952869</td>\n",
       "      <td>0.947047</td>\n",
       "      <td>0.882629</td>\n",
       "      <td>0.872038</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.928713</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00557</th>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.966443</td>\n",
       "      <td>0.822857</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.842767</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00560</th>\n",
       "      <td>0.833977</td>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.513854</td>\n",
       "      <td>0.535433</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.747331</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00619</th>\n",
       "      <td>0.321678</td>\n",
       "      <td>0.308511</td>\n",
       "      <td>0.305419</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.458101</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00645</th>\n",
       "      <td>0.677165</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.903704</td>\n",
       "      <td>0.693182</td>\n",
       "      <td>0.180077</td>\n",
       "      <td>0.473373</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00875</th>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.867133</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.892086</td>\n",
       "      <td>0.904412</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00876</th>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF00906</th>\n",
       "      <td>0.791367</td>\n",
       "      <td>0.836879</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.755245</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF01055</th>\n",
       "      <td>0.862903</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.401460</td>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF01059</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF01705</th>\n",
       "      <td>0.724191</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.703645</td>\n",
       "      <td>0.752161</td>\n",
       "      <td>0.297694</td>\n",
       "      <td>0.309917</td>\n",
       "      <td>0.922889</td>\n",
       "      <td>0.968711</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF01725</th>\n",
       "      <td>0.840764</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.460967</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.578199</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF01739</th>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.218579</td>\n",
       "      <td>0.257669</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF01942</th>\n",
       "      <td>0.963253</td>\n",
       "      <td>0.916482</td>\n",
       "      <td>0.960557</td>\n",
       "      <td>0.975259</td>\n",
       "      <td>0.922137</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.962559</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weigthed avr</th>\n",
       "      <td>0.931862</td>\n",
       "      <td>0.895367</td>\n",
       "      <td>0.928507</td>\n",
       "      <td>0.918679</td>\n",
       "      <td>0.865019</td>\n",
       "      <td>0.858119</td>\n",
       "      <td>0.928603</td>\n",
       "      <td>0.925244</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro avr</th>\n",
       "      <td>0.805788</td>\n",
       "      <td>0.761748</td>\n",
       "      <td>0.791996</td>\n",
       "      <td>0.754931</td>\n",
       "      <td>0.660091</td>\n",
       "      <td>0.661473</td>\n",
       "      <td>0.830838</td>\n",
       "      <td>0.835412</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.929663</td>\n",
       "      <td>0.890365</td>\n",
       "      <td>0.923262</td>\n",
       "      <td>0.910323</td>\n",
       "      <td>0.851824</td>\n",
       "      <td>0.840330</td>\n",
       "      <td>0.924708</td>\n",
       "      <td>0.921473</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  3mer      2mer      1mer     Snake    Morton   Hilbert  \\\n",
       "RF00001       0.942557  0.880391  0.941272  0.931369  0.867303  0.863788   \n",
       "RF00005       0.941100  0.942291  0.941098  0.939531  0.931964  0.919448   \n",
       "RF00015       0.904177  0.909502  0.918269  0.808511  0.819843  0.810458   \n",
       "RF00016       0.941176  0.789157  0.788321  0.784983  0.477157  0.410853   \n",
       "RF00019       0.976242  0.970684  0.977099  0.969957  0.976087  0.975930   \n",
       "RF00020       0.428571  0.154639  0.323353  0.184971  0.131944  0.106977   \n",
       "RF00026       0.967638  0.963437  0.952737  0.970248  0.953297  0.953061   \n",
       "RF00029       0.137931  0.083333  0.047059  0.000000  0.000000  0.034483   \n",
       "RF00050       0.986877  0.914148  0.993412  0.948035  0.980341  0.972621   \n",
       "RF00059       0.968193  0.974704  0.967864  0.962963  0.942308  0.932553   \n",
       "RF00066       0.883562  0.894915  0.724868  0.830189  0.849498  0.765060   \n",
       "RF00097       0.968706  0.958571  0.958042  0.961702  0.852800  0.926756   \n",
       "RF00156       0.704545  0.727273  0.768116  0.744186  0.445498  0.251716   \n",
       "RF00162       0.853242  0.580645  0.972763  0.927419  0.925620  0.815789   \n",
       "RF00169       0.904110  0.943878  0.952128  0.904110  0.792913  0.854167   \n",
       "RF00504       0.943548  0.952869  0.947047  0.882629  0.872038  0.891566   \n",
       "RF00557       0.935897  0.935897  0.966443  0.822857  0.820225  0.934211   \n",
       "RF00560       0.833977  0.837398  0.788321  0.720000  0.513854  0.535433   \n",
       "RF00619       0.321678  0.308511  0.305419  0.454545  0.360000  0.510204   \n",
       "RF00645       0.677165  0.788321  0.903704  0.693182  0.180077  0.473373   \n",
       "RF00875       0.953846  0.867133  0.976190  0.892086  0.904412  0.802632   \n",
       "RF00876       0.606742  0.528302  0.509434  0.459016  0.577778  0.490566   \n",
       "RF00906       0.791367  0.836879  0.765957  0.761905  0.770492  0.755245   \n",
       "RF01055       0.862903  0.860656  0.872000  0.931624  0.750000  0.401460   \n",
       "RF01059       0.947368  0.947368  0.620690  1.000000  0.181818  0.281250   \n",
       "RF01705       0.724191  0.307692  0.703645  0.752161  0.297694  0.309917   \n",
       "RF01725       0.840764  0.797101  0.785714  0.460967  0.787879  0.578199   \n",
       "RF01739       0.456522  0.518519  0.636364  0.218579  0.257669  0.791667   \n",
       "RF01942       0.963253  0.916482  0.960557  0.975259  0.922137  0.833333   \n",
       "Weigthed avr  0.931862  0.895367  0.928507  0.918679  0.865019  0.858119   \n",
       "Macro avr     0.805788  0.761748  0.791996  0.754931  0.660091  0.661473   \n",
       "Accuracy      0.929663  0.890365  0.923262  0.910323  0.851824  0.840330   \n",
       "\n",
       "                  EdeN       nRC Class size  \n",
       "RF00001       0.912135  0.899425       3886  \n",
       "RF00005       0.934906  0.932784       2315  \n",
       "RF00015       0.865217  0.898488        221  \n",
       "RF00016       0.779116  0.859504        134  \n",
       "RF00019       0.980603  0.979280        456  \n",
       "RF00020       0.898876  0.880829         86  \n",
       "RF00026       0.980849  0.973333       1813  \n",
       "RF00029       0.126582  0.133333          5  \n",
       "RF00050       0.967908  0.967658        378  \n",
       "RF00059       0.951275  0.948782       1561  \n",
       "RF00066       0.932384  0.897010        137  \n",
       "RF00097       0.950345  0.958960        717  \n",
       "RF00156       0.773196  0.712871         79  \n",
       "RF00162       0.885714  0.877863        128  \n",
       "RF00169       0.927389  0.879518        381  \n",
       "RF00504       0.928713  0.927711        478  \n",
       "RF00557       0.772727  0.842767         74  \n",
       "RF00560       0.837209  0.747331        111  \n",
       "RF00619       0.556962  0.458101         48  \n",
       "RF00645       0.775000  0.932331         62  \n",
       "RF00875       0.863636  0.922481        125  \n",
       "RF00876       0.636364  0.720000         28  \n",
       "RF00906       0.937500  0.966887         75  \n",
       "RF01055       0.748252  0.815385        111  \n",
       "RF01059       0.692308  0.620690          9  \n",
       "RF01705       0.922889  0.968711        403  \n",
       "RF01725       0.827586  0.726027         66  \n",
       "RF01739       0.763636  0.816327         21  \n",
       "RF01942       0.965035  0.962559        622  \n",
       "Weigthed avr  0.928603  0.925244          -  \n",
       "Macro avr     0.830838  0.835412          -  \n",
       "Accuracy      0.924708  0.921473          -  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tables precision recall f1 and macro/weighted averages \n",
    "# at certain bnoise and n CNN layers \n",
    "\n",
    "from sklearn.metrics import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ExpConfiguration import *\n",
    "\n",
    "# CHANGE HERE plot parameters\n",
    "nl=3  # cnn layer \n",
    "bn = 0 # boundary noise\n",
    "padd = 'New'  # padding to plot\n",
    "\n",
    "v_acc = v_acc_d[padd]\n",
    "y_true = np.argmax(test_labels_bin, axis=1)\n",
    "y_true = le.inverse_transform(y_true)\n",
    "\n",
    "labels,lcounts = np.unique(y_true,return_counts=True)\n",
    "\n",
    "dfs = {}\n",
    "for en in seqEncoders:\n",
    "    y_pred = v_acc[str(nl)][en['filename']][str(bn)]\n",
    "    y_pred = le.inverse_transform(y_pred)\n",
    "    clf1 = f1_score(y_true,y_pred,average=None,labels=labels)\n",
    "    clf1=np.append(clf1,f1_score(y_true,y_pred,average='weighted'))\n",
    "    clf1=np.append(clf1,f1_score(y_true,y_pred,average='macro'))\n",
    "    clf1=np.append(clf1,f1_score(y_true,y_pred,average='micro'))\n",
    "    dfs[en['filename']] = clf1\n",
    "\n",
    "y_pred = np.loadtxt('eden/test_pred_eden_'+str(bn)+'.txt',dtype='str')\n",
    "y_true = np.loadtxt('eden/test_labels_eden_'+str(bn)+'.txt',dtype='str')\n",
    "clf1 = f1_score(y_true,y_pred,average=None,labels=labels)\n",
    "clf1=np.append(clf1,f1_score(y_true,y_pred,average='weighted'))\n",
    "clf1=np.append(clf1,f1_score(y_true,y_pred,average='macro'))\n",
    "clf1=np.append(clf1,f1_score(y_true,y_pred,average='micro'))\n",
    "dfs['EdeN'] = clf1\n",
    "\n",
    "y_pred = np.loadtxt('nrc/test_pred_nrc_'+str(bn)+'.txt',dtype='str')\n",
    "y_true = np.loadtxt('nrc/test_labels_nrc_'+str(bn)+'.txt',dtype='str')\n",
    "clf1 = f1_score(y_true,y_pred,average=None,labels=labels)\n",
    "clf1=np.append(clf1,f1_score(y_true,y_pred,average='weighted'))\n",
    "clf1=np.append(clf1,f1_score(y_true,y_pred,average='macro'))\n",
    "clf1=np.append(clf1,f1_score(y_true,y_pred,average='micro'))\n",
    "dfs['nRC'] = clf1\n",
    "\n",
    "dfs['Class size'] = np.append(lcounts,['-','-','-'])\n",
    "\n",
    "\n",
    "labels = np.append(labels,['Weigthed avr','Macro avr','Accuracy'])\n",
    "df = pd.DataFrame(dfs,index=labels)\n",
    "#df = df.transpose()\n",
    "#df.astype({('nRC','Class size'): 'int32'})\n",
    "\n",
    "with open('tables/prf-table_bn'+str(bn)+'_nl'+str(nl)+'_p'+padd+'.tex','w') as tf:\n",
    "    tf.write(df.to_latex(float_format=\"{:0.2f}\".format))\n",
    "\n",
    "df.to_excel('tables/SupplementalTableS1.xlsx',float_format=\"%.2f\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results with RNAGCN/nRC dataset and improved architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "v_acc_d = {}\n",
    "\n",
    "f = open('results/RNAGCN_nRC_ModelImproved_new.pckl', 'rb')\n",
    "v_acc_d.update({'Improved' : pickle.load(f)})\n",
    "f.close()\n",
    "\n",
    "f = open('results/RNAGCN_nRC_new.pckl', 'rb')\n",
    "v_acc_d.update({'Standard' : pickle.load(f)})\n",
    "f.close()\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "\n",
    "train_labels=np.load(\"dataset_nRC_train_labels.npy\")\n",
    "test_labels=np.load(\"dataset_nRC_test_labels.npy\")\n",
    "\n",
    "num_classes = len(np.unique(train_labels))\n",
    "print('Total classes: ',num_classes)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_num = le.transform(train_labels)\n",
    "test_labels_num = le.transform(test_labels)\n",
    "\n",
    "train_labels_bin = keras.utils.to_categorical(train_labels_num, num_classes)\n",
    "test_labels_bin = keras.utils.to_categorical(test_labels_num, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from ExpConfiguration import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# CHANGE HERE plot parameters\n",
    "bn = 0 # boundary noise\n",
    "padd = 'New'  # padding to plot\n",
    "#pmetric = 'MCC'\n",
    "#pmetricf = matthews_corrcoef\n",
    "pmetric = 'ACC'\n",
    "pmetricf = accuracy_score\n",
    "\n",
    "\n",
    "y_true = np.argmax(test_labels_bin, axis=1)\n",
    "index = ['Standard', 'Improved']\n",
    "cols = {}\n",
    "for en in seqEncoders:\n",
    "    y_pred = v_acc_d['Standard'][en['filename']][str(bn)]\n",
    "    p0 = pmetricf(y_true,y_pred)\n",
    "    y_pred = v_acc_d['Improved'][en['filename']][str(bn)]\n",
    "    p1 = pmetricf(y_true,y_pred)\n",
    "    \n",
    "    performance = [p0,p1]\n",
    "    cols.update({en['filename'] : performance})\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(cols, index=index)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of rejection experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejection experiments figures and tables\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import pickle\n",
    "\n",
    "v_acc_d = {}\n",
    "\n",
    "f = open('results/RejectionExperiments_new.pckl', 'rb')\n",
    "outdata = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "test_labels=np.load(\"test_labels.npy\")\n",
    "num_classes = len(np.unique(test_labels))\n",
    "print('Total classes: ',num_classes)\n",
    "\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_num = le.transform(test_labels)\n",
    "\n",
    "test_labels_bin = keras.utils.to_categorical(test_labels_num, num_classes)\n",
    "\n",
    "y_true = np.argmax(test_labels_bin, axis=1)\n",
    "y_true = le.inverse_transform(y_true)\n",
    "labels,lcounts = np.unique(y_true,return_counts=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Improvement: Distance between two top probs\n",
    "\n",
    "from sklearn.metrics import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ExpConfiguration import *\n",
    "\n",
    "\n",
    "df = pd.DataFrame(index=labels)\n",
    "\n",
    "dfs = {}\n",
    "for en in seqEncoders:\n",
    "    idx=[]\n",
    "    avrp_nornd = outdata[en['filename']]['avrp_nornd']\n",
    "    orderp_nornd = outdata[en['filename']]['orderp_nornd']\n",
    "    var_nornd = outdata[en['filename']]['var_nornd']\n",
    "    \n",
    "    for i in range(len(avrp_nornd)):\n",
    "        l1 = avrp_nornd[i,orderp_nornd[i,0]] - 0.6*np.sqrt(var_nornd[i,orderp_nornd[i,0]])\n",
    "        l2 = avrp_nornd[i,orderp_nornd[i,1]] + 0.6*np.sqrt(var_nornd[i,orderp_nornd[i,1]])\n",
    "        D = l1 - l2\n",
    "        if D>0:\n",
    "            idx.append(i)\n",
    "\n",
    "    y_true_rej = y_true[idx]\n",
    "    y_pred = outdata[en['filename']]['y_pred']\n",
    "    y_pred_rej = y_pred[idx]\n",
    "    clf1 = f1_score(y_true_rej,y_pred_rej,average=None,labels=labels)\n",
    "    #clf1=np.append(clf1,f1_score(y_true_rej,y_pred_rej,average='weighted'))\n",
    "    #clf1=np.append(clf1,f1_score(y_true_rej,y_pred_rej,average='macro'))\n",
    "    #clf1=np.append(clf1,f1_score(y_true_rej,y_pred_rej,average='micro'))\n",
    "    dfs[en['filename']] = clf1\n",
    "\n",
    "    labels_idx,lcounts_idx = np.unique(y_true[idx],return_counts=True)\n",
    "\n",
    "    df[en['filename']] = 0\n",
    "    \n",
    "    df.loc[labels , en['filename']] = lcounts\n",
    "    \n",
    "    df.loc[labels_idx , en['filename']] = df.loc[labels_idx , en['filename']]-lcounts_idx\n",
    "    \n",
    "    df.loc[labels , en['filename']] = 100*df.loc[labels , en['filename']]/lcounts\n",
    "\n",
    "    print(' & %s & %0.2f & %0.2f & %0.2f & %0.2f' % (en['filename'], accuracy_score(y_true_rej,y_pred_rej),\n",
    "                                                                  cohen_kappa_score(y_true_rej,y_pred_rej),\n",
    "                                                                  matthews_corrcoef(y_true_rej,y_pred_rej),\n",
    "                                                                  100*(np.sum(lcounts)-np.sum(lcounts_idx))/np.sum(lcounts)))\n",
    "\n",
    "\n",
    "dfD = pd.DataFrame(dfs,index=labels)\n",
    "dfDrej = df\n",
    "\n",
    "dfDrej.style.background_gradient(cmap='Blues')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Improvement: Entropy\n",
    "\n",
    "from sklearn.metrics import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ExpConfiguration import *\n",
    "\n",
    "\n",
    "df = pd.DataFrame(index=labels)\n",
    "\n",
    "dfs = {}\n",
    "for en in seqEncoders:\n",
    "    idx=[]\n",
    "    hp_nornd = outdata[en['filename']]['hp_nornd']\n",
    "    \n",
    "    for i in range(len(hp_nornd)):\n",
    "        H = hp_nornd[i]\n",
    "        if H < -np.log2(1/num_classes)/3:\n",
    "            idx.append(i)\n",
    "\n",
    "    y_true_rej = y_true[idx]\n",
    "    y_pred = outdata[en['filename']]['y_pred']\n",
    "    y_pred_rej = y_pred[idx]\n",
    "    clf1 = f1_score(y_true_rej,y_pred_rej,average=None,labels=labels)\n",
    "    #clf1=np.append(clf1,f1_score(y_true_rej,y_pred_rej,average='weighted'))\n",
    "    #clf1=np.append(clf1,f1_score(y_true_rej,y_pred_rej,average='macro'))\n",
    "    #clf1=np.append(clf1,f1_score(y_true_rej,y_pred_rej,average='micro'))\n",
    "    dfs[en['filename']] = clf1\n",
    "\n",
    "    labels_idx,lcounts_idx = np.unique(y_true[idx],return_counts=True)\n",
    "\n",
    "    df[en['filename']] = 0\n",
    "    \n",
    "    df.loc[labels , en['filename']] = lcounts\n",
    "    \n",
    "    df.loc[labels_idx , en['filename']] = df.loc[labels_idx , en['filename']]-lcounts_idx\n",
    "    \n",
    "    df.loc[labels , en['filename']] = 100*df.loc[labels , en['filename']]/lcounts\n",
    "    \n",
    "    print(' & %s & %0.2f & %0.2f & %0.2f & %0.2f' % (en['filename'], accuracy_score(y_true_rej,y_pred_rej),\n",
    "                                                                  cohen_kappa_score(y_true_rej,y_pred_rej),\n",
    "                                                                  matthews_corrcoef(y_true_rej,y_pred_rej),\n",
    "                                                                  100*(np.sum(lcounts)-np.sum(lcounts_idx))/np.sum(lcounts)))\n",
    "\n",
    "\n",
    "\n",
    "dfH = pd.DataFrame(dfs,index=labels)\n",
    "dfHrej = df\n",
    "\n",
    "dfH.style.background_gradient(cmap='Blues')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, constrained_layout=True)\n",
    "\n",
    "fig.set_size_inches(9,9)\n",
    "dff1 = dfH\n",
    "df = dfHrej\n",
    "\n",
    "c0 = ax0.imshow(dff1,cmap=\"Blues\",vmax=1,vmin=0,aspect='auto')\n",
    "c1 = ax1.imshow(df,cmap=\"Oranges\",vmax=100,vmin=0,aspect='auto')\n",
    "\n",
    "#ax0.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "ax0.set_yticks(np.arange(len(dff1.index)))\n",
    "ax0.set_yticklabels(dff1.index)\n",
    "ax0.set_ylim(28.5,-0.5)\n",
    "\n",
    "ax0.set_xticks(np.arange(len(dff1.columns)))\n",
    "ax0.set_xticklabels(dff1.columns,fontsize=12)\n",
    "\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "#ax1.set_yticks(np.arange(1,len(df.index)))\n",
    "#ax1.set_yticklabels(df.index)\n",
    "ax1.set_xticks(np.arange(len(df.columns)))\n",
    "ax1.set_xticklabels(df.columns,fontsize=12)\n",
    "\n",
    "\n",
    "fig.suptitle('Entropy Estimator', fontsize=16)\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax0.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "         rotation_mode=\"anchor\",verticalalignment='center')\n",
    "plt.setp(ax1.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "         rotation_mode=\"anchor\",verticalalignment='center')\n",
    "plt.setp(ax0.get_yticklabels(), rotation=0, ha=\"right\",\n",
    "         rotation_mode=\"anchor\",verticalalignment='center')\n",
    "plt.setp(ax1.get_yticklabels(), rotation=0, ha=\"right\",\n",
    "         rotation_mode=\"anchor\",verticalalignment='center')\n",
    "\n",
    "\n",
    "\n",
    "#cax2 = ax1_divider.append_axes(\"top\", size=\"7%\", pad=\"2%\")\n",
    "#cb2 = fig.colorbar(im2, cax=cax2, orientation=\"horizontal\")\n",
    "# change tick position to top. Tick position defaults to bottom and overlaps\n",
    "# the image.\n",
    "#cax2.xaxis.set_ticks_position(\"top\")\n",
    "\n",
    "#c = ax1.pcolor(df)\n",
    "cbar1 = fig.colorbar(c0, ax=ax0,cmap='Blues',location='top')\n",
    "cbar1.set_label('F1-measure', rotation=0, fontsize=12)\n",
    "cbar2 = fig.colorbar(c1, ax=ax1,cmap='Oranges',location='top')\n",
    "cbar2.set_label('% of rejected samples', rotation=0, fontsize=12)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('figs/plot_rej_improvement_H.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax0, ax1, ax2, ax3) = plt.subplots(1, 4, constrained_layout=True)\n",
    "\n",
    "fig.set_size_inches(9,9)\n",
    "dff1 = dfH\n",
    "df = dfHrej\n",
    "\n",
    "c0 = ax0.imshow(dff1,cmap=\"Blues\",vmax=1,vmin=0,aspect='auto')\n",
    "c1 = ax1.imshow(df,cmap=\"Oranges\",vmax=100,vmin=0,aspect='auto')\n",
    "\n",
    "#ax0.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "ax0.set_yticks(np.arange(len(dff1.index)))\n",
    "ax0.set_yticklabels(dff1.index)\n",
    "ax0.set_ylim(28.5,-0.5)\n",
    "ax0.set_title(\"Entropy Estimator\")\n",
    "\n",
    "#ax0.get_xaxis().set_visible(False)\n",
    "ax0.set_xticks(np.arange(len(dff1.columns)))\n",
    "ax0.set_xticklabels(dff1.columns,fontsize=12)\n",
    "\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "#ax1.get_xaxis().set_visible(False)\n",
    "#ax1.set_yticks(np.arange(1,len(df.index)))\n",
    "#ax1.set_yticklabels(df.index)\n",
    "ax1.set_xticks(np.arange(len(df.columns)))\n",
    "ax1.set_xticklabels(df.columns,fontsize=12)\n",
    "\n",
    "\n",
    "\n",
    "#fig.suptitle('Entropy Estimator', fontsize=16)\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax0.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "         rotation_mode=\"anchor\",verticalalignment='center')\n",
    "plt.setp(ax1.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "         rotation_mode=\"anchor\",verticalalignment='center')\n",
    "plt.setp(ax0.get_yticklabels(), rotation=0, ha=\"right\",\n",
    "         rotation_mode=\"anchor\",verticalalignment='center')\n",
    "plt.setp(ax1.get_yticklabels(), rotation=0, ha=\"right\",\n",
    "         rotation_mode=\"anchor\",verticalalignment='center')\n",
    "\n",
    "\n",
    "\n",
    "#cax2 = ax1_divider.append_axes(\"top\", size=\"7%\", pad=\"2%\")\n",
    "#cb2 = fig.colorbar(im2, cax=cax2, orientation=\"horizontal\")\n",
    "# change tick position to top. Tick position defaults to bottom and overlaps\n",
    "# the image.\n",
    "#cax2.xaxis.set_ticks_position(\"top\")\n",
    "\n",
    "#c = ax1.pcolor(df)\n",
    "cbar1 = fig.colorbar(c0, ax=[ax0,ax1],cmap='Blues',shrink=0.6,location='top')\n",
    "cbar1.set_label('F1-measure', rotation=0, fontsize=12)\n",
    "cbar2 = fig.colorbar(c1, ax=[ax2,ax3],cmap='Oranges',shrink=0.6,location='top')\n",
    "cbar2.set_label('% of rejected samples', rotation=0, fontsize=12)\n",
    "\n",
    "\n",
    "dff1 = dfD\n",
    "df = dfDrej\n",
    "\n",
    "c2 = ax2.imshow(dff1,cmap=\"Blues\",vmax=1,vmin=0,aspect='auto')\n",
    "c3 = ax3.imshow(df,cmap=\"Oranges\",vmax=100,vmin=0,aspect='auto')\n",
    "\n",
    "ax2.get_yaxis().set_visible(False)\n",
    "#ax2.set_yticks(np.arange(len(dff1.index)))\n",
    "#ax2.set_yticklabels(dff1.index)\n",
    "#ax2.set_ylim(28.5,-0.5)\n",
    "\n",
    "ax2.set_xticks(np.arange(len(dff1.columns)))\n",
    "ax2.set_xticklabels(dff1.columns,fontsize=12)\n",
    "ax2.set_title(\"Distance Estimator\")\n",
    "\n",
    "\n",
    "ax3.get_yaxis().set_visible(False)\n",
    "#ax1.set_yticks(np.arange(1,len(df.index)))\n",
    "#ax1.set_yticklabels(df.index)\n",
    "ax3.set_xticks(np.arange(len(df.columns)))\n",
    "ax3.set_xticklabels(df.columns,fontsize=12)\n",
    "\n",
    "\n",
    "\n",
    "#fig.suptitle('Entropy Estimator', fontsize=16)\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax2.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "         rotation_mode=\"anchor\",verticalalignment='center')\n",
    "plt.setp(ax3.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "         rotation_mode=\"anchor\",verticalalignment='center')\n",
    "plt.setp(ax2.get_yticklabels(), rotation=0, ha=\"right\",\n",
    "         rotation_mode=\"anchor\",verticalalignment='center')\n",
    "plt.setp(ax3.get_yticklabels(), rotation=0, ha=\"right\",\n",
    "         rotation_mode=\"anchor\",verticalalignment='center')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('figs/plot_rej_improvement_HD.pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "en = '2mer'\n",
    "\n",
    "maxp_rnd = outdata[en]['maxp_rnd']\n",
    "maxp_nornd = outdata[en]['maxp_nornd']\n",
    "\n",
    "pred_score = np.concatenate([maxp_nornd, maxp_rnd])\n",
    "true_class = np.concatenate([np.ones(len(maxp_nornd)), np.zeros(len(maxp_rnd))])\n",
    "\n",
    "\n",
    "ns_auc = roc_auc_score(true_class, pred_score)\n",
    "ns_fpr, ns_tpr, _ = roc_curve(true_class, pred_score)\n",
    "\n",
    "\n",
    "fig, axs = pyplot.subplots(1, 2, constrained_layout=True,figsize=(6,3))\n",
    "fig.suptitle(en, fontsize=16)\n",
    "\n",
    "#pyplot.figure(figsize=(6,3))\n",
    "axs[0].plot(ns_fpr, ns_tpr, linestyle='-')\n",
    "axs[0].text(0.6, 0.2, 'AUC = %.2f' % ns_auc)\n",
    "axs[0].grid(linestyle='--')\n",
    "axs[0].set_xlabel('False Positive Rate')\n",
    "axs[0].set_ylabel('True Positive Rate')\n",
    "\n",
    "axs[1].hist([maxp_nornd, maxp_rnd], bins='auto', density=True, alpha=0.5, label=['Functional seq', 'Random seq'])\n",
    "\n",
    "axs[1].legend(loc='upper left')\n",
    "axs[1].grid(linestyle='--')\n",
    "axs[1].set_xlabel(r'Uncertainty (estimator $p_{max}$)')\n",
    "#\n",
    "pyplot.savefig('figs/plot_rejection_avrp_'+en+'.pdf')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "en = '2mer'\n",
    "\n",
    "maxfp_rnd = outdata[en]['maxfp_rnd']\n",
    "maxfp_nornd = outdata[en]['maxfp_nornd']\n",
    "\n",
    "pred_score = np.concatenate([maxfp_nornd, maxfp_rnd])\n",
    "true_class = np.concatenate([np.ones(len(maxfp_nornd)), np.zeros(len(maxfp_rnd))])\n",
    "\n",
    "\n",
    "\n",
    "ns_auc = roc_auc_score(true_class, pred_score)\n",
    "ns_fpr, ns_tpr, _ = roc_curve(true_class, pred_score)\n",
    "\n",
    "\n",
    "fig, axs = pyplot.subplots(1, 2, constrained_layout=True,figsize=(6,3))\n",
    "fig.suptitle(en, fontsize=16)\n",
    "\n",
    "#pyplot.figure(figsize=(6,3))\n",
    "axs[0].plot(ns_fpr, ns_tpr, linestyle='-')\n",
    "axs[0].text(0.6, 0.2, 'AUC = %.2f' % ns_auc)\n",
    "axs[0].grid(linestyle='--')\n",
    "axs[0].set_xlabel('False Positive Rate')\n",
    "axs[0].set_ylabel('True Positive Rate')\n",
    "\n",
    "axs[1].hist([maxfp_nornd, maxfp_rnd], bins='auto', density=True, alpha=0.5, label=['Functional seq', 'Random seq'])\n",
    "\n",
    "axs[1].legend(loc='upper left')\n",
    "axs[1].grid(linestyle='--')\n",
    "axs[1].set_xlabel(r'Uncertainty (estimator $f_{max}$)')\n",
    "#\n",
    "pyplot.savefig('figs/plot_rejection_fp_'+en+'.pdf')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "en = '1mer'\n",
    "\n",
    "fig, axs = pyplot.subplots(1, 3, constrained_layout=True,figsize=(9,3))\n",
    "#fig.suptitle(en, fontsize=16)\n",
    "\n",
    "hp_rnd = outdata[en]['hp_rnd']\n",
    "hp_nornd = outdata[en]['hp_nornd']\n",
    "\n",
    "pred_score = np.concatenate([-hp_nornd, -hp_rnd])\n",
    "true_class = np.concatenate([np.ones(len(hp_nornd)), np.zeros(len(hp_rnd))])\n",
    "\n",
    "ns_auc = roc_auc_score(true_class, pred_score)\n",
    "ns_fpr, ns_tpr, _ = roc_curve(true_class, pred_score)\n",
    "\n",
    "axs[0].plot(ns_fpr, ns_tpr, linestyle='-',label='Entropy')\n",
    "axs[0].text(0.6, 0.4, 'H AUC = %.2f' % ns_auc)\n",
    "\n",
    "\n",
    "D_nornd=[]\n",
    "avrp_nornd = outdata[en]['avrp_nornd']\n",
    "orderp_nornd = outdata[en]['orderp_nornd']\n",
    "var_nornd = outdata[en]['var_nornd']\n",
    "    \n",
    "for i in range(len(avrp_nornd)):\n",
    "    l1 = avrp_nornd[i,orderp_nornd[i,0]] - 0.6*np.sqrt(var_nornd[i,orderp_nornd[i,0]])\n",
    "    l2 = avrp_nornd[i,orderp_nornd[i,1]] + 0.6*np.sqrt(var_nornd[i,orderp_nornd[i,1]])\n",
    "    D = l1 - l2\n",
    "    D_nornd.append(D)\n",
    "\n",
    "D_rnd=[]\n",
    "avrp_rnd = outdata[en]['avrp_rnd']\n",
    "orderp_rnd = outdata[en]['orderp_rnd']\n",
    "var_rnd = outdata[en]['var_rnd']\n",
    "    \n",
    "for i in range(len(avrp_rnd)):\n",
    "    l1 = avrp_rnd[i,orderp_rnd[i,0]] - 0.6*np.sqrt(var_rnd[i,orderp_rnd[i,0]])\n",
    "    l2 = avrp_rnd[i,orderp_rnd[i,1]] + 0.6*np.sqrt(var_rnd[i,orderp_rnd[i,1]])\n",
    "    D = l1 - l2\n",
    "    D_rnd.append(D)\n",
    "\n",
    "pred_score = np.concatenate([D_nornd, D_rnd])\n",
    "true_class = np.concatenate([np.ones(len(D_nornd)), np.zeros(len(D_rnd))])\n",
    "\n",
    "ns_auc = roc_auc_score(true_class, pred_score)\n",
    "ns_fpr, ns_tpr, _ = roc_curve(true_class, pred_score)\n",
    "\n",
    "\n",
    "axs[0].plot(ns_fpr, ns_tpr, linestyle='-',label='Distance')\n",
    "axs[0].text(0.6, 0.3, 'D AUC = %.2f' % ns_auc)\n",
    "axs[0].grid(linestyle='--')\n",
    "axs[0].set_xlabel('False Positive Rate')\n",
    "axs[0].set_ylabel('True Positive Rate')\n",
    "\n",
    "axs[0].legend(loc='lower right')\n",
    "\n",
    "\n",
    "axs[1].hist([hp_nornd, hp_rnd], bins='auto', density=True, alpha=0.5, label=['Functional seq', 'Random seq'])\n",
    "\n",
    "axs[1].legend(loc='upper right')\n",
    "axs[1].grid(linestyle='--')\n",
    "axs[1].set_xlabel(r'Uncertainty (estimator $H$)')\n",
    "\n",
    "\n",
    "axs[2].hist([D_nornd, D_rnd], bins='auto', density=True, alpha=0.5, label=['Functional seq', 'Random seq'])\n",
    "axs[2].legend(loc='upper left')\n",
    "axs[2].grid(linestyle='--')\n",
    "axs[2].set_xlabel(r'Uncertainty (estimator $D$)')\n",
    "\n",
    "\n",
    "#\n",
    "pyplot.savefig('figs/plot_rejection_HD.pdf')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "en = '1mer'\n",
    "\n",
    "D_nornd=[]\n",
    "avrp_nornd = outdata[en]['avrp_nornd']\n",
    "orderp_nornd = outdata[en]['orderp_nornd']\n",
    "var_nornd = outdata[en]['var_nornd']\n",
    "    \n",
    "for i in range(len(avrp_nornd)):\n",
    "    l1 = avrp_nornd[i,orderp_nornd[i,0]] - 0.6*np.sqrt(var_nornd[i,orderp_nornd[i,0]])\n",
    "    l2 = avrp_nornd[i,orderp_nornd[i,1]] + 0.6*np.sqrt(var_nornd[i,orderp_nornd[i,1]])\n",
    "    D = l1 - l2\n",
    "    D_nornd.append(D)\n",
    "\n",
    "D_rnd=[]\n",
    "avrp_rnd = outdata[en]['avrp_rnd']\n",
    "orderp_rnd = outdata[en]['orderp_rnd']\n",
    "var_rnd = outdata[en]['var_rnd']\n",
    "    \n",
    "for i in range(len(avrp_rnd)):\n",
    "    l1 = avrp_rnd[i,orderp_rnd[i,0]] - 0.6*np.sqrt(var_rnd[i,orderp_rnd[i,0]])\n",
    "    l2 = avrp_rnd[i,orderp_rnd[i,1]] + 0.6*np.sqrt(var_rnd[i,orderp_rnd[i,1]])\n",
    "    D = l1 - l2\n",
    "    D_rnd.append(D)\n",
    "\n",
    "pred_score = np.concatenate([D_nornd, D_rnd])\n",
    "true_class = np.concatenate([np.ones(len(D_nornd)), np.zeros(len(D_rnd))])\n",
    "\n",
    "ns_auc = roc_auc_score(true_class, pred_score)\n",
    "ns_fpr, ns_tpr, _ = roc_curve(true_class, pred_score)\n",
    "\n",
    "\n",
    "fig, axs = pyplot.subplots(2, 1, constrained_layout=True,figsize=(3,6))\n",
    "#fig.suptitle(en, fontsize=16)\n",
    "\n",
    "#pyplot.figure(figsize=(6,3))\n",
    "axs[0].plot(ns_fpr, ns_tpr, linestyle='-')\n",
    "axs[0].text(0.6, 0.2, 'AUC = %.2f' % ns_auc)\n",
    "axs[0].grid(linestyle='--')\n",
    "axs[0].set_xlabel('False Positive Rate')\n",
    "axs[0].set_ylabel('True Positive Rate')\n",
    "\n",
    "axs[1].hist([D_nornd, D_rnd], bins='auto', density=True, alpha=0.5, label=['Functional seq', 'Random seq'])\n",
    "\n",
    "axs[1].legend(loc='upper left')\n",
    "axs[1].grid(linestyle='--')\n",
    "axs[1].set_xlabel(r'Uncertainty (estimator $D$)')\n",
    "#\n",
    "pyplot.savefig('figs/plot_rejection_D_'+en+'.pdf')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
