{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of tables and figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "v_acc_d = {}\n",
    "\n",
    "f = open('results/RfamNovel_constant.pckl', 'rb')\n",
    "v_acc_d.update({'Constant' : pickle.load(f)})\n",
    "f.close()\n",
    "\n",
    "f = open('results/RfamNovel_random.pckl', 'rb')\n",
    "v_acc_d.update({'Random' : pickle.load(f)})\n",
    "f.close()\n",
    "\n",
    "f = open('results/RfamNovel_new.pckl', 'rb')\n",
    "v_acc_d.update({'New' : pickle.load(f)})\n",
    "f.close()\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "train_labels=np.load(\"train_labels.npy\")\n",
    "val_labels=np.load(\"val_labels.npy\")\n",
    "test_labels=np.load(\"test_labels.npy\")\n",
    "\n",
    "num_classes = len(np.unique(train_labels))\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_num = le.transform(train_labels)\n",
    "val_labels_num = le.transform(val_labels)\n",
    "test_labels_num = le.transform(test_labels)\n",
    "\n",
    "train_labels_bin = keras.utils.to_categorical(train_labels_num, num_classes)\n",
    "val_labels_bin = keras.utils.to_categorical(val_labels_num, num_classes)\n",
    "test_labels_bin = keras.utils.to_categorical(test_labels_num, num_classes)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots the accuracy/MCC vs boundary noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots accuracy or MCC VS bnoise\n",
    "from sklearn.metrics import *\n",
    "from ExpConfiguration import *\n",
    "from math import sqrt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "y_true = np.argmax(test_labels_bin, axis=1)\n",
    "\n",
    "# CHANGE HERE plot parameters\n",
    "nl=3  # cnn layer to plot\n",
    "#padd = 'Constant'\n",
    "#padd = 'Random'\n",
    "padd = 'New' \n",
    "#pmetric = 'MCC'\n",
    "#pmetricf = matthews_corrcoef\n",
    "pmetric = 'ACC'\n",
    "pmetricf = accuracy_score\n",
    "\n",
    "v_acc = v_acc_d[padd]\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('Boundary noise')\n",
    "plt.ylabel(pmetric)\n",
    "#plt.title('CNN n. layers = '+str(nl))\n",
    "plt.ylim(0.5, 1) \n",
    "for en in seqEncoders:\n",
    "    mtr=[]\n",
    "    mtrErr=[]\n",
    "    for bn in bnoise:\n",
    "        y_pred = v_acc[str(nl)][en['filename']][str(bn)]\n",
    "        #print('%.3f' % interval)\n",
    "        mtr.append(pmetricf(y_true,y_pred))\n",
    "        mtrErr.append(1.96 * sqrt( (pmetricf(y_true,y_pred) * (1 - pmetricf(y_true,y_pred))) / len(y_pred)))\n",
    "        #print(en['filename'],bn,matthews_corrcoef(y_true,y_pred),accuracy_score(y_true,y_pred))\n",
    "            \n",
    "    ax.plot(bnoise, mtr, label=en['filename'],marker='o',markersize=3)\n",
    "    ax.errorbar(bnoise, mtr, yerr=mtrErr)\n",
    "\n",
    "# add Eden results\n",
    "mtr=[]\n",
    "for bn in bnoise:\n",
    "    y_pred = np.loadtxt('eden/test_pred_eden_'+str(bn)+'.txt',dtype='str')\n",
    "    y_true = np.loadtxt('eden/test_labels_eden_'+str(bn)+'.txt',dtype='str')\n",
    "    mtr.append(pmetricf(y_true,y_pred))\n",
    "    #mtr.append(accuracy_score(y_true,y_pred))\n",
    "    #print('EdeN',bn,matthews_corrcoef(y_true,y_pred),accuracy_score(y_true,y_pred))\n",
    "\n",
    "ax.plot(bnoise, mtr, label='EdeN',marker='o',markersize=3)\n",
    "# add nRC results\n",
    "mtr=[]\n",
    "for bn in bnoise:\n",
    "    y_pred = np.loadtxt('nrc/test_pred_nrc_'+str(bn)+'.txt',dtype='str')\n",
    "    y_true = np.loadtxt('nrc/test_labels_nrc_'+str(bn)+'.txt',dtype='str')\n",
    "    mtr.append(pmetricf(y_true,y_pred))\n",
    "    #print('nRC',bn,matthews_corrcoef(y_true,y_pred),accuracy_score(y_true,y_pred))\n",
    "\n",
    "\n",
    "ax.plot(bnoise, mtr, label='nRC',marker='o',markersize=3)\n",
    "ax.legend()\n",
    "ax.grid(linestyle='--')\n",
    "plt.grid(True)\n",
    "plt.savefig('figs/plot_bnoise-m'+pmetric+'_nl'+str(nl)+'_p'+padd+'.pdf')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots accuracy with different padding schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from ExpConfiguration import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# CHANGE HERE plot parameters\n",
    "nl=3  # cnn layer to plot\n",
    "bn = 0 # boundary noise\n",
    "#pmetric = 'MCC'\n",
    "#pmetricf = matthews_corrcoef\n",
    "pmetric = 'ACC'\n",
    "pmetricf = accuracy_score\n",
    "\n",
    "\n",
    "y_true = np.argmax(test_labels_bin, axis=1)\n",
    "index = ['New', 'Constant', 'Random']\n",
    "cols = {}\n",
    "colsErr = {}\n",
    "for en in seqEncoders:\n",
    "    y_pred = v_acc_d['New'][str(nl)][en['filename']][str(bn)]\n",
    "    pnew = pmetricf(y_true,y_pred)\n",
    "    pnewInt = 1.96 * sqrt( (pnew * (1 - pnew)) / len(y_pred))\n",
    "\n",
    "    y_pred = v_acc_d['Constant'][str(nl)][en['filename']][str(bn)]\n",
    "    pcns = pmetricf(y_true,y_pred)\n",
    "    pcnsInt = 1.96 * sqrt( (pcns * (1 - pcns)) / len(y_pred))\n",
    "\n",
    "    y_pred = v_acc_d['Random'][str(nl)][en['filename']][str(bn)]\n",
    "    prnd = pmetricf(y_true,y_pred)\n",
    "    prndInt = 1.96 * sqrt( (prnd * (1 - prnd)) / len(y_pred))\n",
    "\n",
    "    errors = [pnewInt,pcnsInt,prndInt]\n",
    "    performance = [pnew,pcns,prnd]\n",
    "    cols.update({en['filename'] : performance})\n",
    "    colsErr.update({en['filename'] : errors})\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(cols, index=index)\n",
    "dfErr = pd.DataFrame(colsErr, index=index)\n",
    "ax = df.plot.bar(rot=0,ylim=(0.5,1),yerr=dfErr)\n",
    "ax.grid(linestyle='--')\n",
    "plt.grid(True)\n",
    "ax.legend(loc='lower left')\n",
    "#plt.title('Input padding symbol')\n",
    "plt.ylabel('ACC')\n",
    "plt.savefig('figs/plot-padding.pdf')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots accuracy/MCC with different CNN n. of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from ExpConfiguration import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# CHANGE HERE plot parameters\n",
    "bn = 0 # boundary noise\n",
    "padd = 'New'  # padding to plot\n",
    "#pmetric = 'MCC'\n",
    "#pmetricf = matthews_corrcoef\n",
    "pmetric = 'ACC'\n",
    "pmetricf = accuracy_score\n",
    "\n",
    "\n",
    "y_true = np.argmax(test_labels_bin, axis=1)\n",
    "index = ['0', '1', '2','3']\n",
    "cols = {}\n",
    "for en in seqEncoders:\n",
    "    y_pred = v_acc[str(0)][en['filename']][str(bn)]\n",
    "    p0 = pmetricf(y_true,y_pred)\n",
    "    p0E = 1.96 * sqrt( (p0 * (1 - p0)) / len(y_pred))\n",
    "    y_pred = v_acc[str(1)][en['filename']][str(bn)]\n",
    "    p1 = pmetricf(y_true,y_pred)\n",
    "    p1E = 1.96 * sqrt( (p1 * (1 - p1)) / len(y_pred))\n",
    "\n",
    "    y_pred = v_acc[str(2)][en['filename']][str(bn)]\n",
    "    p2 = pmetricf(y_true,y_pred)\n",
    "    p2E = 1.96 * sqrt( (p2 * (1 - p2)) / len(y_pred))\n",
    "\n",
    "    y_pred = v_acc[str(3)][en['filename']][str(bn)]\n",
    "    p3 = pmetricf(y_true,y_pred)\n",
    "    p3E = 1.96 * sqrt( (p3 * (1 - p3)) / len(y_pred))\n",
    "\n",
    "    \n",
    "    performance = [p0,p1,p2,p3]\n",
    "    errors = [p0E,p1E,p2E,p3E]\n",
    "    cols.update({en['filename'] : performance})\n",
    "    colsErr.update({en['filename'] : errors})\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(cols, index=index)\n",
    "dfErr = pd.DataFrame(colsErr, index=index)\n",
    "ax = df.plot.bar(rot=0,ylim=(0.5,1),yerr=dfErr)\n",
    "ax.grid(linestyle='--')\n",
    "plt.grid(True)\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "#plt.title('CNN number of layers')\n",
    "plt.ylabel('ACC')\n",
    "plt.xlabel('CNN n. of layers')\n",
    "plt.savefig('figs/plot-cnnlayers.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generates tables with precisions, recalls, and F1-measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables precision recall f1 and macro/weighted averages \n",
    "# at certain bnoise and n CNN layers \n",
    "\n",
    "from sklearn.metrics import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ExpConfiguration import *\n",
    "\n",
    "# CHANGE HERE plot parameters\n",
    "nl=3  # cnn layer \n",
    "bn = 0 # boundary noise\n",
    "padd = 'New'  # padding to plot\n",
    "\n",
    "\n",
    "v_acc = v_acc_d[padd]\n",
    "y_true = np.argmax(test_labels_bin, axis=1)\n",
    "y_true = le.inverse_transform(y_true)\n",
    "\n",
    "dfs = {}\n",
    "for en in seqEncoders:\n",
    "    y_pred = v_acc[str(nl)][en['filename']][str(bn)]\n",
    "    y_pred = le.inverse_transform(y_pred)\n",
    "    cr = classification_report(y_true,y_pred,output_dict=True,digits=2)\n",
    "    df1 = pd.DataFrame(cr).drop(index=['support'])\n",
    "    df1.drop(columns=['accuracy'])\n",
    "    df1.index = ['P','R','F1']\n",
    "    df1.drop(index='P')\n",
    "    df1.drop(index='R')\n",
    "    dfs[en['filename']] = df1\n",
    "\n",
    "y_pred = np.loadtxt('eden/test_pred_eden_'+str(bn)+'.txt',dtype='str')\n",
    "y_true = np.loadtxt('eden/test_labels_eden_'+str(bn)+'.txt',dtype='str')\n",
    "cr = classification_report(y_true,y_pred,output_dict=True,digits=2)\n",
    "df1 = pd.DataFrame(cr).drop(index=['support'])\n",
    "df1.drop(columns=['accuracy'])\n",
    "df1.index = ['P','R','F1']\n",
    "df1.drop(index='P')\n",
    "df1.drop(index='R')\n",
    "dfs['EdeN'] = df1\n",
    "\n",
    "y_pred = np.loadtxt('nrc/test_pred_nrc_'+str(bn)+'.txt',dtype='str')\n",
    "y_true = np.loadtxt('nrc/test_labels_nrc_'+str(bn)+'.txt',dtype='str')\n",
    "cr = classification_report(y_true,y_pred,output_dict=True,digits=2)\n",
    "df1 = pd.DataFrame(cr) #.drop(index=['support'])\n",
    "df1.drop(columns=['accuracy'])\n",
    "df1.index = ['P','R','F1','Class size']\n",
    "df1.drop(index='P')\n",
    "df1.drop(index='R')\n",
    "dfs['nRC'] = df1\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df = df.transpose()\n",
    "df.astype({('nRC','Class size'): 'int32'})\n",
    "\n",
    "with open('tables/prf-table_bn'+str(bn)+'_nl'+str(nl)+'_p'+padd+'.tex','w') as tf:\n",
    "    tf.write(df.to_latex(float_format=\"{:0.2f}\".format))\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results with RNAGCN/nRC dataset and improved architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "v_acc_d = {}\n",
    "\n",
    "f = open('results/RNAGCN_nRC_ModelImproved_new.pckl', 'rb')\n",
    "v_acc_d.update({'Improved' : pickle.load(f)})\n",
    "f.close()\n",
    "\n",
    "f = open('results/RNAGCN_nRC_new.pckl', 'rb')\n",
    "v_acc_d.update({'Standard' : pickle.load(f)})\n",
    "f.close()\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "\n",
    "train_labels=np.load(\"dataset_nRC_train_labels.npy\")\n",
    "test_labels=np.load(\"dataset_nRC_test_labels.npy\")\n",
    "\n",
    "num_classes = len(np.unique(train_labels))\n",
    "print('Total classes: ',num_classes)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_num = le.transform(train_labels)\n",
    "test_labels_num = le.transform(test_labels)\n",
    "\n",
    "train_labels_bin = keras.utils.to_categorical(train_labels_num, num_classes)\n",
    "test_labels_bin = keras.utils.to_categorical(test_labels_num, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from ExpConfiguration import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# CHANGE HERE plot parameters\n",
    "bn = 0 # boundary noise\n",
    "padd = 'New'  # padding to plot\n",
    "#pmetric = 'MCC'\n",
    "#pmetricf = matthews_corrcoef\n",
    "pmetric = 'ACC'\n",
    "pmetricf = accuracy_score\n",
    "\n",
    "\n",
    "y_true = np.argmax(test_labels_bin, axis=1)\n",
    "index = ['Standard', 'Improved']\n",
    "cols = {}\n",
    "for en in seqEncoders:\n",
    "    y_pred = v_acc_d['Standard'][en['filename']][str(bn)]\n",
    "    p0 = pmetricf(y_true,y_pred)\n",
    "    y_pred = v_acc_d['Improved'][en['filename']][str(bn)]\n",
    "    p1 = pmetricf(y_true,y_pred)\n",
    "    \n",
    "    performance = [p0,p1]\n",
    "    cols.update({en['filename'] : performance})\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(cols, index=index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
